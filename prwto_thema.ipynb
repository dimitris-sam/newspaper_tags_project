{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the date is smaller. Programm Must STOP\n",
      "the date is smaller. I need to terminate the whole programm\n",
      "[['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση Interview', 'Νέα Δημοκρατία', 'ΠΑΣΟΚ', 'Κυριάκος Μητσοτάκης', 'Αλέξης Τσίπρας', 'Αντώνης Σαμαράς', 'Δημοσκόπηση'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση', 'Δημοσκόπηση Opinion Poll', 'Νέα Δημοκρατία', 'Αλέξης Τσίπρας', 'Πλεύση Ελευθερίας', 'ΠΑΣΟΚ'], ['ΕΛΛΑΔΑ', 'Κύπρος', 'Βλαντιμίρ Πούτιν', 'Σι Τζινπίνγκ', 'Δημοσκόπηση'], ['ΕΛΛΑΔΑ', 'Βία ανηλίκων', 'Μέτρα', 'Πανεπιστήμια', 'Δημοσκόπηση', 'Βία στα Πανεπιστήμια'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση', 'Γκάλοπ', 'Νέα Δημοκρατία', 'ΠΑΣΟΚ'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση', 'Νέα Δημοκρατία', 'Πλεύση Ελευθερίας', 'ΠΑΣΟΚ'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση Interview', 'Νέα Δημοκρατία', 'Κυριάκος Μητσοτάκης', 'ΠΑΣΟΚ', 'Πλεύση Ελευθερίας', 'Δημοσκόπηση'], ['ΚΟΣΜΟΣ', 'Πόλεμος στην Ουκρανία', 'Δημοσκόπηση', 'Ρωσία', 'Βιτάλι Κλίτσκο', 'Ντόναλντ Τραμπ'], ['ΚΟΣΜΟΣ', 'Γαλλία', 'Δημοσκόπηση', 'Εκλογές', 'Γαλλικές εκλογές', 'Προεδρικές εκλογές']]\n",
      "9\n",
      "9\n",
      "the last date is  20250501\n",
      "{'ΠΟΛΙΤΙΚΗ': 5, 'Δημοσκόπηση Interview': 2, 'Νέα Δημοκρατία': 5, 'ΠΑΣΟΚ': 5, 'Κυριάκος Μητσοτάκης': 2, 'Αλέξης Τσίπρας': 2, 'Αντώνης Σαμαράς': 1, 'Δημοσκόπηση': 9, 'Δημοσκόπηση Opinion Poll': 1, 'Πλεύση Ελευθερίας': 3, 'ΕΛΛΑΔΑ': 2, 'Κύπρος': 1, 'Βλαντιμίρ Πούτιν': 1, 'Σι Τζινπίνγκ': 1, 'Βία ανηλίκων': 1, 'Μέτρα': 1, 'Πανεπιστήμια': 1, 'Βία στα Πανεπιστήμια': 1, 'Γκάλοπ': 1, 'ΚΟΣΜΟΣ': 2, 'Πόλεμος στην Ουκρανία': 1, 'Ρωσία': 1, 'Βιτάλι Κλίτσκο': 1, 'Ντόναλντ Τραμπ': 1, 'Γαλλία': 1, 'Εκλογές': 1, 'Γαλλικές εκλογές': 1, 'Προεδρικές εκλογές': 1}\n",
      "[['ΠΟΛΙΤΙΚΗ', 5], ['Δημοσκόπηση Interview', 2], ['Νέα Δημοκρατία', 5], ['ΠΑΣΟΚ', 5], ['Κυριάκος Μητσοτάκης', 2], ['Αλέξης Τσίπρας', 2], ['Αντώνης Σαμαράς', 1], ['Δημοσκόπηση', 9], ['Δημοσκόπηση Opinion Poll', 1], ['Πλεύση Ελευθερίας', 3], ['ΕΛΛΑΔΑ', 2], ['Κύπρος', 1], ['Βλαντιμίρ Πούτιν', 1], ['Σι Τζινπίνγκ', 1], ['Βία ανηλίκων', 1], ['Μέτρα', 1], ['Πανεπιστήμια', 1], ['Βία στα Πανεπιστήμια', 1], ['Γκάλοπ', 1], ['ΚΟΣΜΟΣ', 2], ['Πόλεμος στην Ουκρανία', 1], ['Ρωσία', 1], ['Βιτάλι Κλίτσκο', 1], ['Ντόναλντ Τραμπ', 1], ['Γαλλία', 1], ['Εκλογές', 1], ['Γαλλικές εκλογές', 1], ['Προεδρικές εκλογές', 1]]\n",
      "[20250611, 20250610, 20250527, 20250523, 20250523, 20250514, 20250513, 20250502, 20250501]\n",
      "['11.06.2025', '10.06.2025', '27.05.2025', '23.05.2025', '23.05.2025', '14.05.2025', '13.05.2025', '02.05.2025', '01.05.2025']\n",
      "[['ΠΟΛΙΤΙΚΗ', 20250611], ['Δημοσκόπηση Interview', 20250611], ['Νέα Δημοκρατία', 20250611], ['ΠΑΣΟΚ', 20250611], ['Κυριάκος Μητσοτάκης', 20250611], ['Αλέξης Τσίπρας', 20250611], ['Αντώνης Σαμαράς', 20250611], ['Δημοσκόπηση', 20250611], ['ΠΟΛΙΤΙΚΗ', 20250610], ['Δημοσκόπηση', 20250610], ['Δημοσκόπηση Opinion Poll', 20250610], ['Νέα Δημοκρατία', 20250610], ['Αλέξης Τσίπρας', 20250610], ['Πλεύση Ελευθερίας', 20250610], ['ΠΑΣΟΚ', 20250610], ['ΕΛΛΑΔΑ', 20250527], ['Κύπρος', 20250527], ['Βλαντιμίρ Πούτιν', 20250527], ['Σι Τζινπίνγκ', 20250527], ['Δημοσκόπηση', 20250527], ['ΕΛΛΑΔΑ', 20250523], ['Βία ανηλίκων', 20250523], ['Μέτρα', 20250523], ['Πανεπιστήμια', 20250523], ['Δημοσκόπηση', 20250523], ['Βία στα Πανεπιστήμια', 20250523], ['ΠΟΛΙΤΙΚΗ', 20250523], ['Δημοσκόπηση', 20250523], ['Γκάλοπ', 20250523], ['Νέα Δημοκρατία', 20250523], ['ΠΑΣΟΚ', 20250523], ['ΠΟΛΙΤΙΚΗ', 20250514], ['Δημοσκόπηση', 20250514], ['Νέα Δημοκρατία', 20250514], ['Πλεύση Ελευθερίας', 20250514], ['ΠΑΣΟΚ', 20250514], ['ΠΟΛΙΤΙΚΗ', 20250513], ['Δημοσκόπηση Interview', 20250513], ['Νέα Δημοκρατία', 20250513], ['Κυριάκος Μητσοτάκης', 20250513], ['ΠΑΣΟΚ', 20250513], ['Πλεύση Ελευθερίας', 20250513], ['Δημοσκόπηση', 20250513], ['ΚΟΣΜΟΣ', 20250502], ['Πόλεμος στην Ουκρανία', 20250502], ['Δημοσκόπηση', 20250502], ['Ρωσία', 20250502], ['Βιτάλι Κλίτσκο', 20250502], ['Ντόναλντ Τραμπ', 20250502], ['ΚΟΣΜΟΣ', 20250501], ['Γαλλία', 20250501], ['Δημοσκόπηση', 20250501], ['Εκλογές', 20250501], ['Γαλλικές εκλογές', 20250501], ['Προεδρικές εκλογές', 20250501]]\n",
      "9\n",
      "9\n",
      "[['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση Interview', 'Νέα Δημοκρατία', 'ΠΑΣΟΚ', 'Κυριάκος Μητσοτάκης', 'Αλέξης Τσίπρας', 'Αντώνης Σαμαράς', 'Δημοσκόπηση'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση', 'Δημοσκόπηση Opinion Poll', 'Νέα Δημοκρατία', 'Αλέξης Τσίπρας', 'Πλεύση Ελευθερίας', 'ΠΑΣΟΚ'], ['ΕΛΛΑΔΑ', 'Κύπρος', 'Βλαντιμίρ Πούτιν', 'Σι Τζινπίνγκ', 'Δημοσκόπηση'], ['ΕΛΛΑΔΑ', 'Βία ανηλίκων', 'Μέτρα', 'Πανεπιστήμια', 'Δημοσκόπηση', 'Βία στα Πανεπιστήμια'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση', 'Γκάλοπ', 'Νέα Δημοκρατία', 'ΠΑΣΟΚ'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση', 'Νέα Δημοκρατία', 'Πλεύση Ελευθερίας', 'ΠΑΣΟΚ'], ['ΠΟΛΙΤΙΚΗ', 'Δημοσκόπηση Interview', 'Νέα Δημοκρατία', 'Κυριάκος Μητσοτάκης', 'ΠΑΣΟΚ', 'Πλεύση Ελευθερίας', 'Δημοσκόπηση'], ['ΚΟΣΜΟΣ', 'Πόλεμος στην Ουκρανία', 'Δημοσκόπηση', 'Ρωσία', 'Βιτάλι Κλίτσκο', 'Ντόναλντ Τραμπ'], ['ΚΟΣΜΟΣ', 'Γαλλία', 'Δημοσκόπηση', 'Εκλογές', 'Γαλλικές εκλογές', 'Προεδρικές εκλογές']]\n",
      "the last date collected is  20250501\n",
      "the nr of the tags mentioned is  28\n"
     ]
    }
   ],
   "source": [
    "# Prwto thema\n",
    "\n",
    "# Import necessary libraries for web scraping, browser automation, and data handling\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "# Ask the user for the URL and tag name, build filenames for output CSVs\n",
    "url = input('Give me eplease the URL')\n",
    "tname = input('print the tag name')\n",
    "a = 'Prwto_Thema'\n",
    "b = '_Wdate'\n",
    "csv = '.csv'\n",
    "simple = a+tname+csv\n",
    "wd = a+tname+b+csv\n",
    "\n",
    "# Launch Firefox browser using WebDriver manager\n",
    "driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))\n",
    "\n",
    "# Lists to hold dates and tags from articles\n",
    "date_list = []\n",
    "tag_list = []\n",
    "\n",
    "# The cutoff date - once reached, scraping will stop\n",
    "stop_date = 20250431\n",
    "scroll_pause_time = 2.6\n",
    "\n",
    "# Open the initial URL in the browser\n",
    "driver.get(url)\n",
    "\n",
    "# Give the page time to load and maximize window\n",
    "time.sleep(2)\n",
    "driver.maximize_window()\n",
    "time.sleep(1)\n",
    "\n",
    "# Accept cookies or dismiss popup by clicking \"disagree\" button\n",
    "disagree = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div/div/div[2]/div/button[2]\"))).click()\n",
    "\n",
    "# Flags used to control scraping flow\n",
    "flag = True\n",
    "inside_flag = True\n",
    "\n",
    "# Function to handle scrolling and checking dates while scraping\n",
    "def scroll(driver, timeout):\n",
    "    global flag\n",
    "    global stop_date\n",
    "    global inside_flag\n",
    "    global tag_list\n",
    "    global date_list\n",
    "    scroll_pause_time = timeout\n",
    "\n",
    "    # Number of scrolls before checking the date again\n",
    "    nr_of_scrollings = 2\n",
    "    changable_nr_of_scrollings = nr_of_scrollings\n",
    "\n",
    "    # Check if the date of the latest articles is older than the stop date\n",
    "    def date_check_fun():\n",
    "        global inside_flag\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source,'lxml')\n",
    "        articles_place = soup.find('div' , class_ = \"listLoop\")\n",
    "        dates = articles_place.find_all('div' , class_ = \"wrp\")\n",
    "\n",
    "        # Extract date from last article block\n",
    "        for i in dates:\n",
    "            date = i.find('time')\n",
    "            date = date.get_text()\n",
    "            date = date.split(\",\")\n",
    "            date = date[0].split(\".\")\n",
    "            date.reverse()\n",
    "            date = \"\".join(date)\n",
    "            date = int(date)\n",
    "\n",
    "        # If date is before the stop date, stop scraping\n",
    "        if date < stop_date:\n",
    "            print('the date is smaller. Programm Must STOP')\n",
    "            inside_flag = False\n",
    "            return inside_flag\n",
    "\n",
    "    # Initial scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while inside_flag:\n",
    "        # Scroll to the bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # Check if more content is loaded\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            print('the page reaches the end for the first time. It cannot scroll anymore')\n",
    "            break\n",
    "        last_height = new_height\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # After every few scrolls, check article dates\n",
    "        changable_nr_of_scrollings -= 1\n",
    "        if changable_nr_of_scrollings == 0:\n",
    "            date_check_fun()\n",
    "            changable_nr_of_scrollings = nr_of_scrollings\n",
    "\n",
    "    # Function to extract tags from individual article pages\n",
    "    def tag_fun(inside):\n",
    "        global tag_list\n",
    "        inside_tag_list = []\n",
    "\n",
    "        page = requests.get(inside)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        tags = soup.find('div' , class_ = \"tagsCnt\")\n",
    "        tags = tags.find_all('a')\n",
    "\n",
    "        # Clean and collect each tag\n",
    "        for a in tags:\n",
    "            tag = a.get_text().replace('\\r', \"\").replace('\\n', \"\").strip()\n",
    "            inside_tag_list.append(tag)\n",
    "\n",
    "        tag_list.append(inside_tag_list)\n",
    "\n",
    "    # After scrolling, extract article URLs and dates\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source,'lxml')\n",
    "\n",
    "    articles_place = soup.find('div' , class_ = \"listLoop\")\n",
    "    articles = soup.find_all('article')\n",
    "\n",
    "    for i in articles:\n",
    "        # Extract and convert date\n",
    "        date = i.find('div' , class_ = \"wrp\").find('time').get_text()\n",
    "        date = date.split(\",\")[0].split(\".\")\n",
    "        date.reverse()\n",
    "        date = int(\"\".join(date))\n",
    "\n",
    "        # If date is older than stop_date, stop\n",
    "        if date < stop_date:\n",
    "            print('the date is smaller. I need to terminate the whole programm')\n",
    "            break\n",
    "        else:\n",
    "            # Get full article URL\n",
    "            article_url = i.find('div', class_='heading').find('a').get('href')\n",
    "            https = \"https://www.protothema.gr\"\n",
    "            if article_url.find(https) < 0:\n",
    "                article_url = https + article_url\n",
    "                print('apo katw article url ' , article_url)\n",
    "\n",
    "            date_list.append(date)\n",
    "            tag_fun(article_url)\n",
    "\n",
    "# Start scrolling and scraping process\n",
    "scroll(driver , scroll_pause_time)\n",
    "\n",
    "# Print tag and date info\n",
    "print(tag_list)\n",
    "print(len(tag_list))\n",
    "print(len(date_list))\n",
    "print('the last date is ' , date_list[-1])\n",
    "\n",
    "# ----------- PROCESS AND SAVE TAG FREQUENCIES -----------\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten tag list into a single list\n",
    "new_tag_list = []\n",
    "for i in range(len(tag_list)):\n",
    "    for j in range(len(tag_list[i])):\n",
    "        new_tag_list.append(tag_list[i][j])\n",
    "\n",
    "# Count frequency of each tag\n",
    "res = {}\n",
    "for i in new_tag_list:\n",
    "    res[i] = new_tag_list.count(i)\n",
    "print(res)\n",
    "\n",
    "# Convert dictionary to list of key-value pairs\n",
    "resultList = list(map(list, res.items()))\n",
    "print(resultList)\n",
    "\n",
    "# Save tag counts to CSV\n",
    "df_costliness = pd.DataFrame(resultList)\n",
    "df_costliness.to_csv(simple, header=False)\n",
    "\n",
    "# ----------- PREPARE DATE-TAG PAIRS FOR EXPORT -----------\n",
    "\n",
    "# Create a dot-formatted version of the dates (dd.mm.yyyy)\n",
    "ndlist = []\n",
    "for i in date_list:\n",
    "    i = str(i)\n",
    "    y = i[:4]\n",
    "    m = i[4:6]\n",
    "    d = i[6:]\n",
    "    ddate = d + '.' + m + '.' + y\n",
    "    ndlist.append(ddate)\n",
    "\n",
    "print(date_list)\n",
    "print(ndlist)\n",
    "\n",
    "# Create a list of [tag, date] for all tags\n",
    "n = 0\n",
    "date_con_list = []\n",
    "for i in tag_list:\n",
    "    n += 1\n",
    "    for tag in i:\n",
    "        inside = [tag, date_list[n-1]]\n",
    "        date_con_list.append(inside)\n",
    "\n",
    "print(date_con_list)\n",
    "\n",
    "# Save tag-date pairs to CSV\n",
    "df_connected = pd.DataFrame(date_con_list)\n",
    "df_connected.to_csv(wd, header=False)\n",
    "\n",
    "# Final debug output\n",
    "print(len(tag_list))\n",
    "print(len(date_list))\n",
    "print(tag_list)\n",
    "print('the last date collected is ' , date_list[-1])\n",
    "print('the nr of the tags mentioned is ' , len(resultList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
