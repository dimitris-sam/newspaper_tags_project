{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we reached the date limit\n",
      "nr is  2\n",
      "I have already found the last article man!!\n",
      "[20250605, 20250507, 20250502, 20250430, 20250412, 20250408, 20250328, 20250325, 20250316, 20250314, 20250310, 20250221, 20250220, 20250124, 20250120, 20250113, 20250110, 20241223, 20241221, 20241218]\n",
      "['05.06.2025', '07.05.2025', '02.05.2025', '30.04.2025', '12.04.2025', '08.04.2025', '28.03.2025', '25.03.2025', '16.03.2025', '14.03.2025', '10.03.2025', '21.02.2025', '20.02.2025', '24.01.2025', '20.01.2025', '13.01.2025', '10.01.2025', '23.12.2024', '21.12.2024', '18.12.2024']\n",
      "[['κυβέρνηση', 20250605], ['δημοσκοπήσεις', 20250605], ['ειδήσεις', 20250605], ['ειδήσεις τώρα', 20250605], ['ΠΑΣΟΚ', 20250507], ['ειδήσεις', 20250507], ['Πλεύση Ελευθερίας', 20250507], ['ειδήσεις τώρα', 20250507], ['δημοσκοπήσεις', 20250507], ['δημοσκοπήσεις', 20250502], ['Κυριάκος Μητσοτάκης', 20250502], ['Νέα Δημοκρατία', 20250502], ['ειδήσεις τώρα', 20250502], ['Κυριάκος Μητσοτάκης', 20250430], ['δημοσκοπήσεις', 20250430], ['δημοσκόπηση', 20250430], ['ειδήσεις τώρα', 20250430], ['ΝΔ', 20250412], ['δημοσκοπήσεις', 20250412], ['Κυριάκος Μητσοτάκης', 20250412], ['κυβέρνηση', 20250412], ['ειδήσεις τώρα', 20250412], ['ειδήσεις', 20250412], ['ΠΑΣΟΚ', 20250408], ['ειδήσεις τώρα', 20250408], ['δημοσκοπήσεις', 20250408], ['Νίκος Ανδρουλάκης', 20250408], ['δημοσκοπήσεις', 20250328], ['Τέμπη', 20250328], ['ειδήσεις τώρα', 20250328], ['Νέα Δημοκρατία', 20250328], ['ειδήσεις τώρα', 20250325], ['Τέμπη', 20250325], ['Νέα Δημοκρατία', 20250325], ['δημοσκοπήσεις', 20250325], ['Νίκος Ανδρουλάκης', 20250316], ['ΠΑΣΟΚ', 20250316], ['δημοσκοπήσεις', 20250316], ['ειδήσεις τώρα', 20250316], ['Νέα Δημοκρατία', 20250314], ['δημοσκοπήσεις', 20250314], ['ΣΥΡΙΖΑ', 20250314], ['Σωκράτης Φάμελλος', 20250314], ['Πλεύση Ελευθερίας', 20250314], ['ΠΑΣΟΚ', 20250314], ['δημοσκοπήσεις', 20250310], ['Πλεύση Ελευθερίας', 20250310], ['Ζωή Κωνσταντοπούλου', 20250310], ['ειδήσεις τώρα', 20250310], ['δημοσκόπηση', 20250310], ['δημοσκοπήσεις', 20250221], ['Νέα Δημοκρατία', 20250221], ['ειδήσεις τώρα', 20250221], ['ειδήσεις', 20250220], ['δημοσκοπήσεις', 20250220], ['Τέμπη', 20250220], ['δημοσκόπηση', 20250220], ['Ντόναλντ Τραμπ', 20250124], ['Δημήτρης Κουτσούμπας', 20250124], ['Νίκος Ανδρουλάκης', 20250124], ['Σωκράτης Φάμελλος', 20250124], ['ΚΚΕ', 20250124], ['Κόμμα Νίκη', 20250124], ['Ζωή Κωνσταντοπούλου', 20250124], ['Λούκα Κατσέλη', 20250124], ['Αλέξης Χαρίτσης', 20250124], ['Βασίλης Στίγκας', 20250124], ['Κυριάκος Μητσοτάκης', 20250124], ['Αφροδίτη Λατινοπούλου', 20250124], ['Κωνσταντίνος Τασούλας', 20250124], ['Δημήτρης Νατσιός', 20250124], ['ΣΥΡΙΖΑ', 20250124], ['δημοσκόπηση', 20250124], ['Κυριάκος Βελόπουλος', 20250124], ['Ελληνική Λύση', 20250124], ['Κίνημα Δημοκρατίας', 20250124], ['Πλεύση Ελευθερίας', 20250124], ['Τάσος Γιαννίτσης', 20250124], ['Στέφανος Κασσελάκης', 20250124], ['ΜέΡΑ25', 20250124], ['ΠΑΣΟΚ', 20250124], ['δημοσκοπήσεις', 20250124], ['Φωνή Λογικής', 20250124], ['Νέα Δημοκρατία', 20250124], ['Νέα αριστερά', 20250124], ['μπούλινγκ', 20250120], ['δημοσκοπήσεις', 20250120], ['ειδήσεις τώρα', 20250120], ['τηλεφωνικό κέντρο', 20250120], ['ΠΑΣΟΚ', 20250113], ['Ελληνική Λύση', 20250113], ['Νέα Δημοκρατία', 20250113], ['Φωνή Λογικής', 20250113], ['ειδήσεις τώρα', 20250113], ['Πρόεδρος της Δημοκρατίας', 20250113], ['δημοσκόπηση', 20250113], ['δημοσκοπήσεις', 20250113], ['ΚΚΕ', 20250113], ['ΜέΡΑ25', 20250113], ['Κόμμα Νίκη', 20250113], ['Νέα αριστερά', 20250113], ['ΣΥΡΙΖΑ', 20250113], ['Κίνημα Δημοκρατίας', 20250113], ['Γαλλία', 20250110], ['ειδήσεις', 20250110], ['Εμανουέλ Μακρόν', 20250110], ['δημοσκοπήσεις', 20250110], ['ΣΥΡΙΖΑ', 20241223], ['Νέα Δημοκρατία', 20241223], ['ΠΑΣΟΚ', 20241223], ['δημοσκοπήσεις', 20241223], ['Νίκος Ανδρουλάκης', 20241223], ['ΠΑΣΟΚ', 20241221], ['Νέα Δημοκρατία', 20241221], ['Νέα αριστερά', 20241221], ['Γλύξμπουργκ', 20241221], ['ΣΥΡΙΖΑ', 20241221], ['δημοσκοπήσεις', 20241221], ['Ρεπουμπλικάνοι', 20241218], ['δημοσκοπήσεις', 20241218], ['Αϊόβα', 20241218], ['ειδήσεις τώρα', 20241218], ['εκλογές ΗΠΑ', 20241218], ['ΗΠΑ', 20241218], ['Ντόναλντ Τραμπ', 20241218], ['ειδήσεις', 20241218]]\n",
      "20\n",
      "20\n",
      "[['κυβέρνηση', 'δημοσκοπήσεις', 'ειδήσεις', 'ειδήσεις τώρα'], ['ΠΑΣΟΚ', 'ειδήσεις', 'Πλεύση Ελευθερίας', 'ειδήσεις τώρα', 'δημοσκοπήσεις'], ['δημοσκοπήσεις', 'Κυριάκος Μητσοτάκης', 'Νέα Δημοκρατία', 'ειδήσεις τώρα'], ['Κυριάκος Μητσοτάκης', 'δημοσκοπήσεις', 'δημοσκόπηση', 'ειδήσεις τώρα'], ['ΝΔ', 'δημοσκοπήσεις', 'Κυριάκος Μητσοτάκης', 'κυβέρνηση', 'ειδήσεις τώρα', 'ειδήσεις'], ['ΠΑΣΟΚ', 'ειδήσεις τώρα', 'δημοσκοπήσεις', 'Νίκος Ανδρουλάκης'], ['δημοσκοπήσεις', 'Τέμπη', 'ειδήσεις τώρα', 'Νέα Δημοκρατία'], ['ειδήσεις τώρα', 'Τέμπη', 'Νέα Δημοκρατία', 'δημοσκοπήσεις'], ['Νίκος Ανδρουλάκης', 'ΠΑΣΟΚ', 'δημοσκοπήσεις', 'ειδήσεις τώρα'], ['Νέα Δημοκρατία', 'δημοσκοπήσεις', 'ΣΥΡΙΖΑ', 'Σωκράτης Φάμελλος', 'Πλεύση Ελευθερίας', 'ΠΑΣΟΚ'], ['δημοσκοπήσεις', 'Πλεύση Ελευθερίας', 'Ζωή Κωνσταντοπούλου', 'ειδήσεις τώρα', 'δημοσκόπηση'], ['δημοσκοπήσεις', 'Νέα Δημοκρατία', 'ειδήσεις τώρα'], ['ειδήσεις', 'δημοσκοπήσεις', 'Τέμπη', 'δημοσκόπηση'], ['Ντόναλντ Τραμπ', 'Δημήτρης Κουτσούμπας', 'Νίκος Ανδρουλάκης', 'Σωκράτης Φάμελλος', 'ΚΚΕ', 'Κόμμα Νίκη', 'Ζωή Κωνσταντοπούλου', 'Λούκα Κατσέλη', 'Αλέξης Χαρίτσης', 'Βασίλης Στίγκας', 'Κυριάκος Μητσοτάκης', 'Αφροδίτη Λατινοπούλου', 'Κωνσταντίνος Τασούλας', 'Δημήτρης Νατσιός', 'ΣΥΡΙΖΑ', 'δημοσκόπηση', 'Κυριάκος Βελόπουλος', 'Ελληνική Λύση', 'Κίνημα Δημοκρατίας', 'Πλεύση Ελευθερίας', 'Τάσος Γιαννίτσης', 'Στέφανος Κασσελάκης', 'ΜέΡΑ25', 'ΠΑΣΟΚ', 'δημοσκοπήσεις', 'Φωνή Λογικής', 'Νέα Δημοκρατία', 'Νέα αριστερά'], ['μπούλινγκ', 'δημοσκοπήσεις', 'ειδήσεις τώρα', 'τηλεφωνικό κέντρο'], ['ΠΑΣΟΚ', 'Ελληνική Λύση', 'Νέα Δημοκρατία', 'Φωνή Λογικής', 'ειδήσεις τώρα', 'Πρόεδρος της Δημοκρατίας', 'δημοσκόπηση', 'δημοσκοπήσεις', 'ΚΚΕ', 'ΜέΡΑ25', 'Κόμμα Νίκη', 'Νέα αριστερά', 'ΣΥΡΙΖΑ', 'Κίνημα Δημοκρατίας'], ['Γαλλία', 'ειδήσεις', 'Εμανουέλ Μακρόν', 'δημοσκοπήσεις'], ['ΣΥΡΙΖΑ', 'Νέα Δημοκρατία', 'ΠΑΣΟΚ', 'δημοσκοπήσεις', 'Νίκος Ανδρουλάκης'], ['ΠΑΣΟΚ', 'Νέα Δημοκρατία', 'Νέα αριστερά', 'Γλύξμπουργκ', 'ΣΥΡΙΖΑ', 'δημοσκοπήσεις'], ['Ρεπουμπλικάνοι', 'δημοσκοπήσεις', 'Αϊόβα', 'ειδήσεις τώρα', 'εκλογές ΗΠΑ', 'ΗΠΑ', 'Ντόναλντ Τραμπ', 'ειδήσεις']]\n",
      "the last date collected is  20241218\n",
      "the nr of the tags mentioned is  43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ETHNOS\n",
    "\n",
    "# Required imports\n",
    "from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys  # Not used\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# User inputs for the URL and tag name\n",
    "url = input('Enter please the url of the main page ')\n",
    "tname = input('print the tag name')\n",
    "\n",
    "# File naming setup\n",
    "a = 'Ethnos'\n",
    "b = '_Wdate'\n",
    "csv = '.csv'\n",
    "simple = a + tname + csv\n",
    "wd = a + tname + b + csv\n",
    "\n",
    "# Initialize lists and stopping date\n",
    "date_list = []\n",
    "tag_list = []\n",
    "stop_date = 20241201\n",
    "\n",
    "# Initialize Firefox WebDriver\n",
    "driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "# Handle cookies pop-up by clicking 'Disagree'\n",
    "disagree = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div/div/div[2]/div/button[2]\"))).click()\n",
    "\n",
    "# Scroll to the \"Load more\" button initially to make it visible\n",
    "load_button = driver.find_element(By.CLASS_NAME, \"read-more-posts\")\n",
    "driver.execute_script(\"arguments[0].scrollIntoView(false);\", load_button)\n",
    "time.sleep(1.5)\n",
    "\n",
    "# Function to dynamically update the XPath for the \"Load more\" button\n",
    "xpath = '/html/body/div[2]/main/div[2]/div[1]/div[1]/div[1]/div/div[12]/button'\n",
    "def new_button_xpath():\n",
    "    global xpath\n",
    "    digits = xpath[59:63]\n",
    "    while digits.isdigit() == False:\n",
    "        digits = digits[:-1]\n",
    "    nr_of_digits = len(digits)\n",
    "    digits = int(digits) + 9\n",
    "    digits = str(digits)\n",
    "    xpath = xpath[:59] + digits + xpath[59 + nr_of_digits:]\n",
    "\n",
    "# Function that checks the date of the last article on the page to determine whether to stop\n",
    "def scrolling_date_check(driver, stop_date):\n",
    "    global flag\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    suggested_articles = soup.find('div', class_='main-content')\n",
    "    date_check = suggested_articles.find_all('div', class_='single-post-container')[-1]\n",
    "    date_check = date_check.find('div', class_='single-category')\n",
    "    article_time = date_check.find_all(\"a\")[1].get_text()\n",
    "    new_date = article_time[:-6].split('.')\n",
    "    new_date.reverse()\n",
    "    for i in range(len(new_date)):\n",
    "        if '\\n' in new_date[i]:\n",
    "            new_date[i] = new_date[i][-2:]\n",
    "    new_date = \"\".join(new_date)\n",
    "    try:\n",
    "        new_date = int(new_date)\n",
    "    except ValueError:\n",
    "        new_date = article_time[:-6].split('/')\n",
    "        new_date.reverse()\n",
    "        new_date = int(\"\".join(new_date))\n",
    "    if new_date < stop_date:\n",
    "        print('we reached the date limit')\n",
    "        flag = False\n",
    "\n",
    "# Function to collect tags and dates from visible articles\n",
    "def collecting_fun(driver):\n",
    "    global tag_list\n",
    "    global date_list\n",
    "\n",
    "    def tag_function(inside):\n",
    "        global tag_list\n",
    "        page = requests.get(inside)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        lifestyle = soup.find_all('div', class_='category')\n",
    "        try:\n",
    "            if len(lifestyle) > 1:\n",
    "                print('vrika xalasmeno arhtro. Lifestyle Magazine')\n",
    "                print('its url is ', inside)\n",
    "                print('Please check the url i gave you..')\n",
    "            else:\n",
    "                tag_section = soup.find('ul', class_='list-inline tags-list')\n",
    "                b = tag_section.find_all(\"a\")\n",
    "                inside_tag_list = []\n",
    "                for a in b:\n",
    "                    tag = a.get_text()\n",
    "                    inside_tag_list.append(tag)\n",
    "                tag_list.append(inside_tag_list)\n",
    "        except:\n",
    "            print('vrika xalasmeno arthro')\n",
    "            print('Please check for broken url: ', inside)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    suggested_articles = soup.find('div', class_='main-content')\n",
    "\n",
    "    # Iterate through articles\n",
    "    for h in suggested_articles('div', class_='single-post-container'):\n",
    "        date_check = h.find('a')\n",
    "        date_check = h.find('div', class_='single-category')\n",
    "        single_category = date_check.find_all('a')\n",
    "        article_time = single_category[1].get_text()\n",
    "        new_date = article_time[:-6].split('.')\n",
    "        new_date.reverse()\n",
    "        for i in range(len(new_date)):\n",
    "            if '\\n' in new_date[i]:\n",
    "                new_date[i] = new_date[i][-2:]\n",
    "        new_date = \"\".join(new_date)\n",
    "        try:\n",
    "            new_date = int(new_date)\n",
    "        except ValueError:\n",
    "            new_date = article_time[:-6].split('/')\n",
    "            new_date.reverse()\n",
    "            new_date = int(\"\".join(new_date))\n",
    "        if new_date < stop_date:\n",
    "            print('I have already found the last article man!!')\n",
    "            break\n",
    "        else:\n",
    "            inside_tag_list = []\n",
    "            date_list.append(new_date)\n",
    "            outer_tag = single_category[0].get_text()\n",
    "            inside_tag_list.append(outer_tag)\n",
    "            article_url = h.find('a').get('href')\n",
    "            https = \"https://www.ethnos.gr\"\n",
    "            if https not in article_url:\n",
    "                article_url = https + article_url\n",
    "            else:\n",
    "                continue\n",
    "            tag_function(article_url)\n",
    "            time.sleep(0.3)\n",
    "\n",
    "# Scrolling loop: keeps clicking \"Load more\" and checks dates\n",
    "nr_of_button_pressed_times = 2\n",
    "nr_of_button_pressed_count = nr_of_button_pressed_times\n",
    "flag = True\n",
    "nr = 0  # number of scrolls\n",
    "\n",
    "while flag:\n",
    "    load_button = driver.find_element(By.XPATH, xpath)\n",
    "    try:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(false);\", load_button)\n",
    "        time.sleep(1.5)\n",
    "        load_more = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, xpath))).click()\n",
    "    except TimeoutException:\n",
    "        print('load button cannot be found. Probably we reached the end of scrolling. \\n No more articles appear')\n",
    "        flag = False\n",
    "    time.sleep(1)\n",
    "    nr_of_button_pressed_count -= 1\n",
    "    if nr_of_button_pressed_count == 0:\n",
    "        scrolling_date_check(driver, stop_date)\n",
    "        nr_of_button_pressed_count = nr_of_button_pressed_times\n",
    "    nr += 1\n",
    "    new_button_xpath()\n",
    "    time.sleep(1)\n",
    "\n",
    "print('nr is ', nr)\n",
    "\n",
    "# After scrolling is done, collect all tags and dates\n",
    "collecting_fun(driver)\n",
    "\n",
    "# Processing tag list and date list into DataFrames and exporting to CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten tag list into a single list for counting\n",
    "new_tag_list = []\n",
    "for i in range(len(tag_list)):\n",
    "    for j in range(len(tag_list[i])):\n",
    "        new_tag_list.append(tag_list[i][j])\n",
    "\n",
    "# Count frequency of each tag\n",
    "res = {}\n",
    "for i in new_tag_list:\n",
    "    res[i] = new_tag_list.count(i)\n",
    "\n",
    "# Convert the tag-frequency dictionary to a list for DataFrame\n",
    "resultList = list(map(list, res.items()))\n",
    "df_costliness = pd.DataFrame(resultList)\n",
    "df_costliness.to_csv(simple, header=False)\n",
    "\n",
    "# Convert int date format (yyyymmdd) to dotted format (dd.mm.yyyy)\n",
    "ddate_list = date_list\n",
    "ttag_list = tag_list\n",
    "ndlist = []\n",
    "for i in ddate_list:\n",
    "    i = str(i)\n",
    "    y = i[:4]\n",
    "    m = i[4:6]\n",
    "    d = i[6:]\n",
    "    ddate = d + '.' + m + '.' + y\n",
    "    ndlist.append(ddate)\n",
    "\n",
    "print(ddate_list)\n",
    "print(ndlist)\n",
    "\n",
    "# Connect each tag with its corresponding article date\n",
    "n = 0\n",
    "date_con_list = []\n",
    "for i in ttag_list:\n",
    "    n += 1\n",
    "    for tag in i:\n",
    "        inside = []\n",
    "        inside.append(tag)\n",
    "        inside.append(ddate_list[n - 1])\n",
    "        date_con_list.append(inside)\n",
    "\n",
    "print(date_con_list)\n",
    "\n",
    "df_connected = pd.DataFrame(date_con_list)\n",
    "df_connected.to_csv(wd, header=False)\n",
    "\n",
    "# Final output logs\n",
    "print(len(tag_list))\n",
    "print(len(date_list))\n",
    "print(tag_list)\n",
    "print('the last date collected is ', date_list[-1])\n",
    "print('the nr of the tags mentioned is ', len(resultList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
